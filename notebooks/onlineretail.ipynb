{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import random\n",
    "\n",
    "import implicit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-0813e2997076>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_retail['CustomerID'] = cleaned_retail.CustomerID.astype(int) # Convert to int for customer ID\n",
      "C:\\Users\\mullmann\\.conda\\envs\\recosys\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('../data/raw/' + 'online_retail/OnlineRetail.xlsx')\n",
    "cleaned_retail = df.loc[pd.isnull(df.CustomerID) == False]\n",
    "item_lookup = cleaned_retail[['StockCode', 'Description']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['StockCode'] = item_lookup.StockCode.astype(str)\n",
    "\n",
    "cleaned_retail['CustomerID'] = cleaned_retail.CustomerID.astype(int) # Convert to int for customer ID\n",
    "cleaned_retail = cleaned_retail[['StockCode', 'Quantity', 'CustomerID']] # Get rid of unnecessary info\n",
    "grouped_cleaned = cleaned_retail.groupby(['CustomerID', 'StockCode']).sum().reset_index() # Group together\n",
    "grouped_cleaned.Quantity.loc[grouped_cleaned.Quantity == 0] = 1 # Replace a sum of zero purchases with a one to\n",
    "# indicate purchased\n",
    "grouped_purchased = grouped_cleaned.query('Quantity > 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "customer_list = list(np.sort(grouped_purchased.CustomerID.unique()))\n",
    "product_list = list(grouped_purchased.StockCode.unique())\n",
    "cat_customers = CategoricalDtype(categories=customer_list, ordered=True) # Get our unique customers\n",
    "cat_products = CategoricalDtype(categories=product_list, ordered=True) # Get our unique products that were purchased\n",
    "quantity = list(grouped_purchased.Quantity) # All of our purchases\n",
    "\n",
    "\n",
    "\n",
    "rows = grouped_purchased.CustomerID.astype(cat_customers).cat.codes\n",
    "# Get the associated row indices\n",
    "cols = grouped_purchased.StockCode.astype(cat_products).cat.codes\n",
    "# Get the associated column indices\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customer_list), len(product_list)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<4338x3664 sparse matrix of type '<class 'numpy.float64'>'\n\twith 266723 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchases_sparse\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings,\n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix.\n",
    "\n",
    "    parameters:\n",
    "\n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix.\n",
    "\n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the\n",
    "    training set for later comparison to the test set, which contains all of the original ratings.\n",
    "\n",
    "    returns:\n",
    "\n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs\n",
    "    that originally had interaction set back to zero.\n",
    "\n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order\n",
    "    compares with the actual interactions.\n",
    "\n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set.\n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set.\n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test = 0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2b9c3e0705149b1ac66f647e122386b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 15\n",
    "user_vecs, item_vecs = implicit.alternating_least_squares((product_train*alpha).astype('double'),\n",
    "                                                          factors=20,\n",
    "                                                          regularization = 0.1,\n",
    "                                                         iterations = 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics.\n",
    "\n",
    "    parameters:\n",
    "\n",
    "    - predictions: your prediction output\n",
    "\n",
    "    - test: the actual target result you are comparing to\n",
    "\n",
    "    returns:\n",
    "\n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered.\n",
    "\n",
    "    parameters:\n",
    "\n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model\n",
    "\n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one.\n",
    "\n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "\n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "\n",
    "\n",
    "\n",
    "    returns:\n",
    "\n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "\n",
    "\n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1)\n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training\n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "\n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))\n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.869, 0.814)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(product_train, product_users_altered,\n",
    "              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-60ebdc1e",
   "language": "python",
   "display_name": "PyCharm (recosys)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}